U050M5F75 : oh rllllly
U050M5F75 : i did not know that
U051SS2EU : ```+user=&gt; (java.util.Date.)#inst "2017-07-04T13:25:33.376-00:00"
+user=&gt; #inst "1492-01-10T12:11:44.000-00:00"
#inst "1492-01-10T12:11:44.000-00:00"
```

U051SS2EU : Date is a less than great API, but clojure makes it readable
U050M5F75 : does this `#inst` mean <https://clojure.github.io/clojure/clojure.instant-api.html>?
U051SS2EU : no, it's how Date objects are printed, its the instant reader
U0K1UT6PQ : I confirm the fishiness, was pulling a dependency in the code :facepalm:
U0K1UT6PQ : so that was fun
U050M5F75 : this is cool. didnt know about `#inst` and `#uuid` and stuff
U050M5F75 : thx
U3QUAHZJ6 : hello everyone, i have 4 heavy database queries that are running sequentially
```
      (benefit-db/transition-benefits-to-ongoing db/db-spec)
      (benefit-db/transition-benefits-to-consumed db/db-spec)
      (benefit-db/transition-benefits-to-ended db/db-spec)
```


is there an easy way to run this guys in parallel and do something else when they *all* finish?

U2PGHFU5U : plins: `(let [results (map deref  [(future trans1) (future trans2)  (future trans3)] do-something-else))`
U06C1JGHX : hey all… for a number of strange reasons I want to create an instance of a class whose name I only have as a string. How would I instantiate one?
U050SC7SV : either via a macro or reflection possibly
U06C1JGHX : cheers <@U050SC7SV>. I just found `Class/forName` which does what I'm after
U050SC7SV : (.newInstance (Class/forName "foo.bar.baz"))
U050SC7SV : yes :slightly_smiling_face:
U0524B4UW : tho `(.newInstance (Class/forName "foo.bar.baz"))` only seems to have a 0-args sig
U0524B4UW : ah, you have to use `.getDeclaredConstructor` on the `Class` object to get the constructor method and then call that
U06BV1HCH : Do multiple threads just reading from (derefing) an atom that has a constant value block or cause any kind of contention?
U0NCTKEV8 : no
U06BV1HCH : Awesome -- so should be the same as just reading a var?
U06BV1HCH : in terms of multithread contention
U0NCTKEV8 : that is kind of complicated, they are different things. my intuition would be that vars would be ever so slightly faster before the jit has kicked in, and an atom would be ever so slightly faster after
U0NCTKEV8 : but they are different things, not drop in replacements for each other
U06BV1HCH : understood. the story is that we have a system with config data in atoms, which are constant after configuration, and our multicore scaling is bad. the question came up of whether billions of accesses to  constant-valued atoms might be causing contention. the alternative we're considering isn't actually to use a var (actually, we'd get rid of the vars that currently hold the atoms), but just to pass all of the config data as an argument throughout the system. it'll be a relatively big job to try this, so i'm trying to figure out if the underlying theory is even true, that reading (derefing) the atom in a var can cause contention among threads.
U051SS2EU : atoms contain an AtomicReference <https://github.com/clojure/clojure/blob/master/src/jvm/clojure/lang/Atom.java#L20> and use the get method to access their value <https://docs.oracle.com/javase/7/docs/api/java/util/concurrent/atomic/AtomicReference.html#get()>
U051SS2EU : get on an AtomicReference is the same overhead as reading a volatile, which sources claim is cheap
U051SS2EU : this should also be easy to microbenchmark though
U0NCTKEV8 : you should actually hook something like visualvm and look at the hot methods
U0NCTKEV8 : don't just guess
U0NCTKEV8 : if your configs are in global atoms, then you are dereferencing both the var containing the atom and the atom
U051SS2EU : that's a good point, based on profiling I've done I'd expect the var lookup to be more expensive than the atom deref
U0NCTKEV8 : I mean for the config thing
U0NCTKEV8 : for vars vs. atoms, without the jit, my guess is the atoms still have to traverse a few extra pointers for access, but with the jit I expect it is a regular reference that just uses atomic instructions
U0NCTKEV8 : (I don't know, I haven't profiled it or looked at the code the jit produces)
U0NCTKEV8 : but I would expect just about anything else to dominate those differences
U0D33A4JF : there should also be some improvement with direct linking on
U0NCTKEV8 : direct linking is only for functions
U051SS2EU : fwiw the differences are pretty small once the JIT has kicked in ```+user=&gt; (let [a (atom 42)] (reduce (fn [_ ft] @ft) (repeatedly 10000 #(future @a))))42
+user=&gt; (let [a (atom 42)] (crit/bench (reduce (fn [_ ft] @ft) (repeatedly 10000 #(future @a)))))
Evaluation count : 900 in 60 samples of 15 calls.
             Execution time mean : 91.621587 ms
    Execution time std-deviation : 11.931053 ms
   Execution time lower quantile : 57.841222 ms ( 2.5%)
   Execution time upper quantile : 106.129733 ms (97.5%)
                   Overhead used : 1.534327 ns

Found 4 outliers in 60 samples (6.6667 %)
        low-severe       4 (6.6667 %)
 Variance from outliers : 80.6424 % Variance is severely inflated by outliers
nil
+user=&gt; (def a (atom 42))
#'user/a
:user=&gt; (crit/bench (reduce (fn [_ ft] @ft) (repeatedly 10000 #(future @a))))
Evaluation count : 600 in 60 samples of 10 calls.
             Execution time mean : 97.601813 ms
    Execution time std-deviation : 11.193445 ms
   Execution time lower quantile : 73.574920 ms ( 2.5%)
   Execution time upper quantile : 116.281827 ms (97.5%)
                   Overhead used : 1.534327 ns

Found 1 outliers in 60 samples (1.6667 %)
        low-severe       1 (1.6667 %)
 Variance from outliers : 75.5029 % Variance is severely inflated by outliers
nil
+user=&gt; (crit/bench (reduce (fn [_ ft] @ft) (repeatedly 10000 #(future *clojure-version*))))
Evaluation count : 780 in 60 samples of 13 calls.
             Execution time mean : 99.271467 ms
    Execution time std-deviation : 8.236914 ms
   Execution time lower quantile : 78.021114 ms ( 2.5%)
   Execution time upper quantile : 111.492377 ms (97.5%)
                   Overhead used : 1.534327 ns

Found 4 outliers in 60 samples (6.6667 %)
        low-severe       1 (1.6667 %)
        low-mild         3 (5.0000 %)
 Variance from outliers : 61.8161 % Variance is severely inflated by outliers
nil
```

U051SS2EU : that's comparing - direct access to atom and deref, access of atom in var and deref, and access to a value in a var
U051SS2EU : the futures are because there was concern about contention
U0NCTKEV8 : obviously what you should do is preprocess your config in to a primitive array, and generate macros for accessing each config value that expand in to agets of the right array slot
U06BV1HCH : all very interesting! point well taken about checking data before optimizing, and we have a lot of work to do on that front
U06BV1HCH : it seems from the discussion here this use of atoms in vars probably isn't producing contention, right?
U051SS2EU : right- no evidence of contention there at all
U06BV1HCH : fwiw the alternative we're considering would be function args, rather than vars, with the config passed everywhere
U06BV1HCH : awesome, thx!!
U051SS2EU : I realize I didn't benchmark just having a data literal - checking that now to see if there's any difference worth noticing


in above conversation, code/s mentioned has issue/s?
	If Yes:
	1.Bad	2.Very bad
	If No:
	1.Good	2.Very good


How confident are you?
	1.Low
	2.Average
	3.High

Optional!
can you highlight place/word/sentence which lead to your decision
